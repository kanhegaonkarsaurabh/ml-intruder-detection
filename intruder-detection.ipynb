{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "# for math\n",
    "import numpy as np\n",
    "# for plotting the clusters\n",
    "import matplotlib.pyplot as plt\n",
    "# animating cluster movements\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset which lists the DDoS attack frquencies and packets sent per second\n",
    "def load_dataset(name):\n",
    "    return np.loadtxt(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/dc0281a964ec758cca02ab9ef91a7f54ac00d4b7 \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The above formula: Define the distance between two points.\n",
    "def euclidian_dist(a,b):\n",
    "    return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(k, epsilon=0, distance=\"euclidian\"):\n",
    "    # Define all the hyperparameters needed for the algorithm\n",
    "    \n",
    "    # All the centroid values so that they can be plotted\n",
    "    history_centroids = []\n",
    "    \n",
    "    dist_method = euclidian_dist\n",
    "    \n",
    "    # Load the dataset and get the number of points and features selected\n",
    "    dataset = load_dataset('durudataset.txt')\n",
    "    num_instances, num_features = dataset.shape\n",
    "    \n",
    "    # Load in an initial set of random clusters and store them in the history\n",
    "    prototypes = dataset[np.random.randint(0, num_instances-1, size=k)]\n",
    "    history_centroids.append(prototypes)\n",
    "    prototypes_old = np.zeros(prototypes.shape)\n",
    "    belongs_to = np.zeros((num_instances, 1))\n",
    "    # define the euclidian distances between all the points in the clusters\n",
    "    norm = dist_method(prototypes, prototypes_old)\n",
    "    iteration = 0\n",
    "    while norm > epsilon:\n",
    "        iteration += 1\n",
    "        norm = dist_method(prototypes, prototypes_old)\n",
    "        #for each instance in the dataset\n",
    "        for index_instance, instance in enumerate(dataset):\n",
    "            #define a distance vector of size k\n",
    "            dist_vec = np.zeros((k,1))\n",
    "            #for each centroid\n",
    "            for index_prototype, prototype in enumerate(prototypes):\n",
    "                #compute the distance between x and centroid\n",
    "                dist_vec[index_prototype] = dist_method(prototype, instance)\n",
    "            #find the smallest distance, assign that distance to a cluster\n",
    "            belongs_to[index_instance, 0] = np.argmin(dist_vec)\n",
    "            \n",
    "        tmp_prototypes = np.zeros((k, num_features))\n",
    "        \n",
    "        #for each cluster (k of them)\n",
    "        for index in range(len(prototypes)):\n",
    "            #get all the points assigned to a cluster\n",
    "            instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "            #find the mean of those points, this is our new centroid\n",
    "            prototype = np.mean(dataset[instances_close], axis=0)\n",
    "            #add our new centroid to our new temporary list\n",
    "            tmp_prototypes[index, :] = prototype\n",
    "        \n",
    "        #set the new list to the current list\n",
    "        prototypes = tmp_prototypes\n",
    "        \n",
    "        #add our calculated centroids to our history for plotting\n",
    "        history_centroids.append(tmp_prototypes)\n",
    "\n",
    "    #return calculated centroids, history of them all, and assignments for which cluster each datapoint belongs to\n",
    "    return prototypes, history_centroids, belongs_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets define a plotting algorithm for our dataset and our centroids\n",
    "def plot(dataset, history_centroids, belongs_to):\n",
    "    #we'll have 2 colors for each centroid cluster\n",
    "    colors = ['r', 'g']\n",
    "\n",
    "    #split our graph by its axis and actual plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    #for each point in our dataset\n",
    "    for index in range(dataset.shape[0]):\n",
    "        #get all the points assigned to a cluster\n",
    "        instances_close = [i for i in range(len(belongs_to)) if belongs_to[i] == index]\n",
    "        #assign each datapoint in that cluster a color and plot it\n",
    "        for instance_index in instances_close:\n",
    "            ax.plot(dataset[instance_index][0], dataset[instance_index][1], (colors[index] + 'o'))\n",
    "\n",
    "    #lets also log the history of centroids calculated via training\n",
    "    history_points = []\n",
    "    #for each centroid ever calculated\n",
    "    for index, centroids in enumerate(history_centroids):\n",
    "        #print them all out\n",
    "        for inner, item in enumerate(centroids):\n",
    "            if index == 0:\n",
    "                history_points.append(ax.plot(item[0], item[1], 'bo')[0])\n",
    "            else:\n",
    "                history_points[inner].set_data(item[0], item[1])\n",
    "                print(\"centroids {} {}\".format(index, item))\n",
    "\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#main file \n",
    "def execute():\n",
    "    #load dataset\n",
    "    dataset = load_dataset('durudataset.txt')\n",
    "    #train the model on the data\n",
    "    centroids, history_centroids, belongs_to = kmeans(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
